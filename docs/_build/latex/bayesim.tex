%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
 \ifdefined\DeclareUnicodeCharacterAsOptional
  \DeclareUnicodeCharacter{"00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{"2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{"2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{"2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{"251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{"2572}{\textbackslash}
 \else
  \DeclareUnicodeCharacter{00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{2572}{\textbackslash}
 \fi
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}

\addto\extrasenglish{\def\pageautorefname{page}}



\definecolor{firebrick}{rgb}{0.7, 0.13, 0.13} \definecolor{darkorange}{rgb}{1.0, 0.55, 0.0} \definecolor{darkmagenta}{rgb}{0.55, 0.0, 0.55}

\title{bayesim Documentation}
\date{Oct 31, 2018}
\release{0.9.5}
\author{Rachel C Kurchin and Giuseppe Romano}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex

\begin{document}

\maketitle
\sphinxtableofcontents
\phantomsection\label{\detokenize{index::doc}}



\chapter{Getting Started}
\label{\detokenize{gettingstarted:getting-started}}\label{\detokenize{gettingstarted::doc}}

\section{Prerequisites}
\label{\detokenize{gettingstarted:prerequisites}}
\sphinxcode{\sphinxupquote{bayesim}} has been most thoroughly tested in Python 3.6.


\section{Download}
\label{\detokenize{gettingstarted:download}}
To install bayesim simply type

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
pip install bayesim
\end{sphinxVerbatim}


\section{Usage}
\label{\detokenize{gettingstarted:usage}}
For more details on both usage methods described below, see the {\hyperref[\detokenize{manual::doc}]{\sphinxcrossref{\DUrole{doc}{Manual}}}}.


\subsection{Python / Jupyter}
\label{\detokenize{gettingstarted:python-jupyter}}
The easiest way to learn how \sphinxcode{\sphinxupquote{bayesim}} works is by stepping through one of the {\hyperref[\detokenize{examples::doc}]{\sphinxcrossref{\DUrole{doc}{Examples}}}}, which have well-commented \sphinxhref{http://jupyter.org}{Jupyter notebooks} associated with them and can be run in \sphinxhref{https://mybinder.org}{binder} with no need to install Python, \sphinxcode{\sphinxupquote{bayesim}}, or any of its dependencies locally.

If you are comfortable coding in Python, these examples will also make it clear how to script using \sphinxcode{\sphinxupquote{bayesim}}.


\subsection{Command line}
\label{\detokenize{gettingstarted:command-line}}
A command line interface will be implemented in a future release!


\chapter{Why bayesim?}
\label{\detokenize{whybayesim:why-bayesim}}\label{\detokenize{whybayesim::doc}}
There are plenty of tools already out there for Bayesian parameter estimation. What’s special/useful about \sphinxcode{\sphinxupquote{bayesim}}? What is it good for? What \sphinxstyleemphasis{isn’t} it good for?

I won’t reinvent the wheel of the Bayesian/frequentist debate here because many smarter people have written a lot about it in other places. Instead, I’ll just emphasize a couple important points, the first of which is general to the approach, and the second of which is specific to how \sphinxcode{\sphinxupquote{bayesim}} implements it.


\section{Probability distributions are nice}
\label{\detokenize{whybayesim:probability-distributions-are-nice}}
The output of a \sphinxcode{\sphinxupquote{bayesim}} analysis is not just a set of values and uncertainties, but rather a full multidimensional probability distribution. The power of this comes when the regions of parameter space that have highest probability are not simple ellipsoidal blobs with axes along the parameter axes, but instead take on more complicated shapes that can reflect underlying tradeoffs between fitting parameters. For example, in our research group’s \sphinxhref{https://www.sciencedirect.com/science/article/pii/S254243511730096X}{first published paper using Bayesian parameter estimation} (which used a much earlier precursor of the code that was eventually developed into \sphinxcode{\sphinxupquote{bayesim}}), we found that of the four parameters we fit, two were constrained quite well, while two others didn’t seem to be on an individual basis:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{SnS_probs}.png}
\caption{Figure 3 from \sphinxhref{https://www.sciencedirect.com/science/article/pii/S254243511730096X}{this paper}. The \(\Delta E_c\) and \(S_\text{eff}\) parameters are constrained well, while \(\mu\) and \(\tau\) exhibit a much larger spread in their individual distributions (red and yellow histograms).}\label{\detokenize{whybayesim:id1}}\end{figure}

However, when we look at the two-parameter marginalization of the final posterior distribution (second plot from the right on the bottom row), we see that while the values of \(\mu\) and \(\tau\) may not have been individually well-constrained, their \sphinxstyleemphasis{product} was pinned quite well. As it happens, this product is related to a quantity known as the \sphinxstyleemphasis{electron diffusion length}, and under the conditions we measured the solar cell, other effects that \(\mu\) and \(\tau\) have on performance were small enough that they couldn’t be decoupled from each other.

This type of insight could not be gleaned from a more traditional parameter fitting approach such as a least-squares regression and requires the ability to see the probability distribution over parameters.


\section{Simulations are expensive}
\label{\detokenize{whybayesim:simulations-are-expensive}}
A very common approach to multidimensional Bayesian parameter estimation involves Monte Carlo (MC) sampling rather than sampling on a grid as we do here. In general, such approaches scale very well to larger numbers of dimensions and hence may have great appeal (“larger numbers” is problem dependent but for “typical” problems if you have more than 10 parameters to estimate, an MC approach is preferable). Bayesim uses adaptive grid sampling, which has two major benefits over MC sampling for relatively low-dimensional problems:
\begin{enumerate}
\item {}
It can be significantly less computationally expensive (from a more formal numerical perspective, it avoids the generally large prefactor in cost estimates for MC sampling, which can overwhelm the dimensional savings when the dimensionality is small) and

\item {}
There is significantly less uncertainty that all regions of non-negligible probability are quickly detected, since the coarsest iteration tends to identify all “hotspots” immediately, provided the {\hyperref[\detokenize{bayesics:model-uncertainty}]{\sphinxcrossref{\DUrole{std,std-ref}{model uncertainty}}}} associated with the sampling density is incorporated.

\end{enumerate}

The take-home message here is that \sphinxcode{\sphinxupquote{bayesim}}’s \sphinxstylestrong{approach shines in situations where the computational effort required to evaluate the likelihood is large, as when the data models are sophisticated numerical solvers, and the number of fitting parameters is (relatively) small.}

Many of the {\hyperref[\detokenize{examples::doc}]{\sphinxcrossref{\DUrole{doc}{Examples}}}} we show here involve analytical models, however. This is done only to create examples that are tractable to run in a few seconds on a typical personal computer. In reality, while \sphinxcode{\sphinxupquote{bayesim}} certainly works with these models, it is unlikely to be the most efficient approach to fitting their parameters. In addition, with an analytical model, tradeoffs such as the one between \(\mu\) and \(\tau\) described above are generally already apparent from the mathematical form of the model and hence the final probability distribution isn’t necessarily required for such insights.


\chapter{Technical Background}
\label{\detokenize{bayesics:technical-background}}\label{\detokenize{bayesics::doc}}
This page includes some references about Bayes’ Theorem and Bayesian inference and discusses the particulars of the implementation of these ideas within \sphinxcode{\sphinxupquote{bayesim}}.


\section{Bayes’ Theorem}
\label{\detokenize{bayesics:bayes-theorem}}
There are a \sphinxhref{https://brohrer.github.io/how\_bayesian\_inference\_works.html}{plethora} of \sphinxhref{https://brilliant.org/wiki/bayes-theorem/}{great} \sphinxhref{https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/}{explanations} of Bayes’ Theorem out there already, so I won’t go through all the bayesics here but instead refer you to one of those linked above or any number of others you can find online or in a textbook.

Assuming you understand Bayes’ Theorem to your own satisfaction at this point, let’s remind ourselves of some \sphinxstylestrong{terminology}.
\begin{equation}\label{equation:bayesics:bayesics:0}
\begin{split}\color{firebrick} {P(H|E)} =
\frac{\color{darkorange} {P(H)}
\color{darkmagenta} {P(E|H)}}
{\color{teal} {P(E)}}\end{split}
\end{equation}
The \(\color{firebrick}{\mathbf{\text{posterior probability}}}\) of our hypothesis \(H\) given observed evidence \(E\) is the result of a Bayesian update to the \(\color{darkorange}{\mathbf{\text{prior}}}\) estimate of the probability of \(H\) given the \(\color{darkmagenta}{\mathbf{\text{likelihood}}}\) of observing \(E\) in a world where \(H\) is true and the probability of observing our \(\color{teal}{\mathbf{\text{evidence}}}\) in the first place.


\section{Bayesian Inference and Parameter Estimation}
\label{\detokenize{bayesics:bayesian-inference-and-parameter-estimation}}
\begin{sphinxadmonition}{note}{Note:}
I haven’t found an online explanation of this material at a not-excessively-mathy level (I firmly believe that you don’t need a lot of knowledge of mathematical terminology to understand this; it can really be done in a very visual way) so I wrote my own. If you know of another, please \sphinxhref{mailto:rkurchin@mit.edu}{send it to me} and I’d be happy to link to it here!

\sphinxstylestrong{Update!!} I found some nice explanations/examples in \sphinxhref{https://github.com/jakevdp/BayesianAstronomy}{this repo}! Check them out for some more material in addition to what I’ve included here.
\end{sphinxadmonition}

Most of the examples used to explain Bayes’ Theorem have two hypotheses to disginguish between (e.g. “is it raining?”: yes or no). However, to use Bayes’ Theorem for \sphinxstyleemphasis{parameter estimation}, which is the problem of interest here, we need to generalize to many more than two hypotheses, and those hypotheses may be about the values of multiple different parameters. In addition, we would like to incorporate many pieces of evidence, necessitating many iterations of the Bayesian calculation. These and other factors can make it confusing to conceptualize how to generalize the types of computations we do to estimate the probability of the answer to a yes-or-no question or a dice roll to a problem statement relevant to a more general scientific/modeling inquiry. I will walk through these factors here.


\subsection{Many hypotheses, in multiple dimensions}
\label{\detokenize{bayesics:many-hypotheses-in-multiple-dimensions}}
The first step is let our hypotheses \(H\) range over more than two values. That is, rather than having \(H_1\) = “yes, it is raining” and \(H_2\) = “no, it is not raining”, we would instead have something like \(H_1\) = “the value of parameter \(A\) is \(a_1\)“, \(H_2\) = “the value of parameter \(A\) is \(a_2\)“, etc. for as many \(a_n\) as we wanted to consider. While we could then in principle enumerate many different statements of Bayes’ Theorem of the form

\begin{eqnarray}
  \label{equation:bayesics:bayesics:1}
P(A=a_1|E) &=& \frac{P(A=a_1)P(E|A=a_1)}{P(E)} \\
P(A=a_2|E) &=& \frac{P(A=a_2)P(E|A=a_2)}{P(E)} \\
&...& \\
P(A=a_n|E) &=& \frac{P(A=a_n)P(E|A=A_n)}{P(E)}
\end{eqnarray}
this is quite cumbersome and so instead we will write
\begin{equation}\label{equation:bayesics:bayesics:2}
\begin{split}P(A|E) = \frac{P(A)P(E|A)}{P(E)}\end{split}
\end{equation}
with the understanding that this probability is not a single value but rather a function over all possible values of \(A\). This also allows the number of equations we have to write not to explode when we want to add another fitting parameter, and instead the probability function just to be defined over an additional dimension:
\begin{equation}\label{equation:bayesics:bayesics:3}
\begin{split}P(A,B|E) = \frac{P(A,B)P(E|A,B)}{P(E)}\end{split}
\end{equation}

\subsection{Iterative Bayesian updates}
\label{\detokenize{bayesics:iterative-bayesian-updates}}
The next step is to reframe Bayes’ Theorem as an explicitly iterative procedure. Imagine we’ve incorporated one piece of evidence \(E_1\), resulting in a posterior probability \(P(H|E_1)\). To update our posterior again given further observation \(E_2\), we simply let this \sphinxstyleemphasis{posterior} become our new \sphinxstyleemphasis{prior}:
\begin{equation}\label{equation:bayesics:bayesics:4}
\begin{split}P(H|\{E_1,E_2\}) = \frac{P(H|E_1)P(E_2|H)}{P(E_2)}\end{split}
\end{equation}
Hopefully now it’s easy to see that for \sphinxstyleemphasis{n} pieces of evidence, we can say that
\begin{equation}\label{equation:bayesics:bayesics:5}
\begin{split}P(H|\{E_1,E_2,...E_n\}) = \frac{P(H|\{E_1,E_2...E_{n-1}\})P(E_n|H)}{P(E_n)}\end{split}
\end{equation}

\subsection{Where does the likelihood come from?!? Data modeling!}
\label{\detokenize{bayesics:where-does-the-likelihood-come-from-data-modeling}}
At this point, it would be natural to say “Sure, that math all makes sense, but how do I actually \sphinxstyleemphasis{know} what that likelihood \(P(E|H)\) \sphinxstyleemphasis{is?!?}”

This is where having a \sphinxstylestrong{model} of our experimental observations comes in. This model could take many forms - it might be a simple analytical equation, or it might be a sophisticated numerical solver. The key traits are that it can accurately predict the outcome of a measurement on your system as as function of all relevant experimental conditions as well as fitting parameters of interest.

More specifically, suppose your measurement yields some output variable \(O\) as a function of various experimental conditions \{\(C\)\}. Then your evidence looks like
\begin{equation}\label{equation:bayesics:bayesics:6}
\begin{split}O(C_1, C_2,...C_n)\end{split}
\end{equation}
Suppose also that you have a set of model parameters \{\(P\)\} that you wish to know the values of. That means that your posterior distribution after \(m\) observations will look something like
\begin{equation}\label{equation:bayesics:bayesics:7}
\begin{split}P(P_1, P_2,...P_l|O_1,O_2...O_m)\end{split}
\end{equation}
where the hypotheses are sets of values of the parameters \{\(P\)\}, i.e., points in the fitting parameter space. Then your \sphinxstylestrong{model} must take the form
\begin{equation}\label{equation:bayesics:bayesics:8}
\begin{split}M(\{P_1, P_2,...P_l\},\{C_1, C_2,...C_n\}) = O\end{split}
\end{equation}
Given an observation \(O_m\) at conditions \{\(C_1^m,C_2^m,...C_n^m\)\} (where the \(m\) superscript indicates specific values of the conditions rather than their full ranges), we can compute the likelihood over all parameters \{\(P\)\} by evaluating our model for these conditions \{\(C^m\)\} and comparing the simulated outputs \{\(M(\{P\},\{C^m\})\)\} to the measured output \(O_m\). But then how do we know what probabilities to assign as a function of how much the measured and simulated outputs differ? Glad you asked…


\subsection{Experimental Uncertainty}
\label{\detokenize{bayesics:experimental-uncertainty}}
Our experimental measurement \(O_m\) will have some associated uncertainty \(\Delta O\), generally a known property of our equipment/measurement technique. Quantifying this uncertainty is key to understanding how to calculate likelihoods. Specifically, we need to introduce an \sphinxstylestrong{error model}. We’ll use a Gaussian distribution, a very common pattern for experimental errors in all kinds of measurements:
\begin{equation}\label{equation:bayesics:bayesics:9}
\begin{split}P(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\end{split}
\end{equation}
where \(\mu\) is the \sphinxstylestrong{mean}, \(\sigma\) is the \sphinxstylestrong{standard deviation}, and the term in front of the exponential is just a normalizing constant (to make sure that the probability distribution integrates to 1). The distribution looks like this:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.6]{{720px-Normal_Distribution_PDF}.png}
\caption{You can see the impact of the two parameters - a larger \(\sigma\) value makes the distribution wider, while \(\mu\) simply shifts the center. (Image from \sphinxhref{https://en.wikipedia.org/wiki/Normal\_distribution}{Wikipedia}.)}\label{\detokenize{bayesics:id2}}\end{figure}

What this means for our example is that our measurement of some value \(O_m^0\) for our output parameter \(O\) is converted to a distribution of possible “true” values for \(O_m\):
\begin{equation}\label{equation:bayesics:bayesics:10}
\begin{split}P(O_m) \propto \exp\left({-\frac{(O_m-O_m^0)^2}{2*\Delta O^2}}\right)\end{split}
\end{equation}
(I’m leaving off the normalization constant for convenience.)


\subsection{Model Uncertainty}
\label{\detokenize{bayesics:model-uncertainty}}\label{\detokenize{bayesics:id1}}
Of course, when our model function isn’t a simple analytical equation but rather a numerical solver of some sort, we can’t evaluate it on a continuous parameter space but we instead have to discretize the space into a grid and choose points on that grid at which to simulate. This introduces a so-called “model uncertainty” proportional to the magnitude of the variation in the model output as one moves around the fitting parameter space. This model uncertainty is calculated in \sphinxcode{\sphinxupquote{bayesim}} at each experimental condition for each point in the parameter space as the largest change in model output from that point to any of the immediately adjacent points.

Then, when we compute likelihoods, we use the sum of these two uncertainties as the standard deviation of our Gaussian.

Especially if the parameter space grid is coarse, incorporating this model uncertainty is critical - if the variation in output variable from one grid point to another is significantly larger than the experimental uncertainty but this uncertainty is used as the standard deviation, it is possible that likelihood could be computed as zero everywhere in the parameter space, just because the measured output corresponded to parameters between several of the chosen sample points. And that wouldn’t be very good.


\section{An illustrative example: Kinematics}
\label{\detokenize{bayesics:an-illustrative-example-kinematics}}
This probably all seems a bit abstract at this point, so illustrate how we do this in practice, let’s use a simple example. Suppose we want to estimate the value of \(g\), the acceleration due to gravity near Earth’s surface, and \(v_0\), the initial velocity of a vertically launched projectile (e.g. a ball tossed straight up), based on some measured data about the trajectory of the ball. We know from basic kinematics that the height of the ball as a function of time should obey (assuming that the projectile’s initial height is defined as 0)
\begin{equation}\label{equation:bayesics:bayesics:11}
\begin{split}y(t) = v_0t - \frac 12 gt^2\end{split}
\end{equation}
This function represents our \sphinxstylestrong{model} of the data we will measure and we can equivalently write
\begin{equation}\label{equation:bayesics:bayesics:12}
\begin{split}M(v_0, g; t) = v_0t - \frac 12 gt^2\end{split}
\end{equation}
where we’ve now explicitly delineated our parameters \(g\) and \(v_0\) and our measurement condition \(t\).

Now let’s suppose we make a measurement after 2 seconds of flight and find that \(y(2)=3\), with an uncertainty in the measurement of 0.2. Recalling our Gaussian error model from above, we can write
\begin{equation}\label{equation:bayesics:bayesics:13}
\begin{split}P(y(2)) \propto \exp\left({-\frac{(y(2)-3)^2}{2*0.2^2}}\right)\end{split}
\end{equation}
(Assume model uncertainty is negligible.) But what we \sphinxstyleemphasis{really} want is a probability distribution over our parameters, not over the measurement value itself. Fortunately, our model function lets us do just that! We can translate our distribution over possible measured values into one over possible parameter values using the model function:
\begin{eqnarray}
  \label{equation:bayesics:condprob}
P(v_0, g | y(2)=3 \pm 0.2) & \propto & \exp\left({-\frac{(M(v_0,g;2)-3)^2}{2*0.2^2}}\right) \\
& \propto & \exp\left({-\frac{(2v_0 - 2g - 3)^2}{0.08}}\right)
\end{eqnarray}
Now we can visualize what that distribution looks like in “\(v_0\)-\(g\)” space:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{probs_1}.png}
\caption{On the left, the probability distribution over a wide range of possible values. On the right, zoomed in to near the true value of \(g\) to show Gaussian spread.}\label{\detokenize{bayesics:id3}}\end{figure}

Another way we might want to visualize would be in the space of what the actual trajectories look like:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{trajs}.png}
\caption{On the left, \(y(t)\) trajectories from \(t=0\) to \(t=3\). On the right, zooming in on the region indicated to see spread around \sphinxtitleref{y(2)=3}.}\label{\detokenize{bayesics:id4}}\end{figure}

So we can see that what the inference step did was essentially “pin” the trajectories to go through (or close to) the measured point at (\sphinxstyleemphasis{t},*y*)=(2.0,3.0).

Now let’s suppose we take another measurement, a short time later: \sphinxstyleemphasis{y(2.3)=0.1}, but with a larger uncertainty, this time of 0.5. Now we return to Bayes’ Theorem - our prior distribution will be the conditional distribution from Equation \eqref{equation:bayesics:condprob} above, and the likelihood will be a new conditional distribution generated in exactly the same way but for this new data point. What does the posterior look like?

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{probs_2}.png}
\caption{(Note that the axis limits are smaller than above)}\label{\detokenize{bayesics:id5}}\end{figure}

As we would expect, we’re starting to zero in on a smaller region. And how about the trajectories?

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{trajs_2}.png}
\caption{Newly refined set of trajectories shown in red, overlaid on (paler) larger set from the previous step.}\label{\detokenize{bayesics:id6}}\end{figure}

As expected, we’ve further winnowed down the possible trajectories. If we continued this process for more and more measurements, eventually zeroing in on the correct values with greater and greater precision.

To see this example as implemented in \sphinxcode{\sphinxupquote{bayesim}}, check out the {\hyperref[\detokenize{examples::doc}]{\sphinxcrossref{\DUrole{doc}{Examples}}}} page!


\chapter{Manual}
\label{\detokenize{manual:manual}}\label{\detokenize{manual::doc}}

\section{Overview}
\label{\detokenize{manual:overview}}
The basic procedure of performing a parameter fit with \sphinxcode{\sphinxupquote{bayesim}} is as follows:

\begin{figure}[htbp]
\centering

\noindent\sphinxincludegraphics[scale=0.6]{{flowchart_b}.png}
\end{figure}

On this page, we will dive into each part of this flowchart in detail to understand what is happening and what options exist to tweak \sphinxcode{\sphinxupquote{bayesim}}’s behavior. The code snippets will be assuming that we are modeling a solar cell’s output current \(J\) with two experimental conditions: voltage \(V\) and temperature \(T\).

The first step is to initialize a \sphinxcode{\sphinxupquote{Model}} object. Several of the next steps can be rolled into this initialization using keywords, but the only required input is the name of the output variable. For example:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{bayesim.model} \PYG{k+kn}{as} \PYG{n+nn}{bym}
\PYG{n}{m} \PYG{o}{=} \PYG{n}{bym}\PYG{o}{.}\PYG{n}{Model}\PYG{p}{(}\PYG{n}{output\PYGZus{}var}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{J}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Attaching Observations}
\label{\detokenize{manual:attaching-observations}}\label{\detokenize{manual:attach-obs}}
The experimental observations should reside in an HDF5 file with columns for each experimental condition and the output variable. Optionally, there may also be a column for experimental uncertainty. In addition, one should specify one of the experimental conditions (EC’s) to be plotted on the x-axis when visualizing data later on using the \sphinxcode{\sphinxupquote{ec\_x\_var}} keyword. The data are attached using:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{attach\PYGZus{}observations}\PYG{p}{(}\PYG{n}{obs\PYGZus{}data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{obs\PYGZus{}data.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{ec\PYGZus{}x\PYGZus{}var}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{V}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

If this column isn’t present, the \sphinxcode{\sphinxupquote{fixed\_unc}} keyword must be passed with a value to use as experimental uncertainty for every data point:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{attach\PYGZus{}observations}\PYG{p}{(}\PYG{n}{obs\PYGZus{}data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{obs\PYGZus{}data.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{ec\PYGZus{}x\PYGZus{}var}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{V}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fixed\PYGZus{}unc}\PYG{o}{=}\PYG{l+m+mf}{0.02}\PYG{p}{)}
\end{sphinxVerbatim}

By default, to save computational time, \sphinxcode{\sphinxupquote{bayesim}} will not import all data points, but rather attempt to maintain some minimum spacing between points such that each piece of evidence is more likely to contribute to constraining the posterior distribution. This behavior can be turned off by passing \sphinxcode{\sphinxupquote{keep\_all=True}} to the \sphinxcode{\sphinxupquote{attach\_observations()}} function, and can be tuned using the \sphinxcode{\sphinxupquote{max\_ec\_x\_step}} and \sphinxcode{\sphinxupquote{thresh\_dif\_frac}} keywords. \sphinxcode{\sphinxupquote{thresh\_dif\_frac}} is given as a fraction of the range of values of the output variable and defaults to 0.01. It defines the minimum difference in output variable along the x-axis EC (at fixed values of the other EC’s) for which to save a point. \sphinxcode{\sphinxupquote{max\_ec\_x\_step}} is the largest step to take in the previously defined x-axis EC before saving a point anyway even if it \sphinxstyleemphasis{doesn’t} differ by that threshold amount, and defaults to 5\% of the range of values of the x-axis EC. Let’s look at an example case where we use the default values for these parameters:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{import_example}.png}
\caption{Note how in the ‘flatter’ region of the curve, the spacing along the x-axis of imported points is wider than in the ‘steeper’ region.}\label{\detokenize{manual:id1}}\end{figure}


\section{Defining Parameters}
\label{\detokenize{manual:defining-parameters}}
It is possible to predefine the parameter grid by directly constructing a \sphinxcode{\sphinxupquote{Param\_list}} object and passing it to the \sphinxcode{\sphinxupquote{Model}} constructor, although this is not necessary, because \sphinxcode{\sphinxupquote{bayesim}} is capable of determining these directly from the model data file (see next step). However, if one wants to use \sphinxcode{\sphinxupquote{bayesim}} to generate the list of model points that need to be simulated, this approach is useful. Consider the {\hyperref[\detokenize{examples:id}]{\sphinxcrossref{\DUrole{std,std-ref}{ideal diode}}}} example, where the parameters to be fit were \(B'\) and \(n\):

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{bayesim.model} \PYG{k+kn}{as} \PYG{n+nn}{bym}
\PYG{k+kn}{import} \PYG{n+nn}{bayesim.params} \PYG{k+kn}{as} \PYG{n+nn}{byp}
\PYG{n}{pl} \PYG{o}{=} \PYG{n}{byp}\PYG{o}{.}\PYG{n}{Param\PYGZus{}list}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{pl}\PYG{o}{.}\PYG{n}{add\PYGZus{}fit\PYGZus{}param}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Bp}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{display\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{B}\PYG{l+s+s2}{\PYGZsq{}}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{val\PYGZus{}range}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{1000}\PYG{p}{]}\PYG{p}{,} \PYG{n}{spacing}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{log}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{length}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{units}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{arb.}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{pl}\PYG{o}{.}\PYG{n}{add\PYGZus{}fit\PYGZus{}param}\PYG{p}{(}\PYG{n}{name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{n}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{val\PYGZus{}range}\PYG{o}{=}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,}\PYG{l+m+mi}{2}\PYG{p}{]}\PYG{p}{,} \PYG{n}{length}\PYG{o}{=}\PYG{l+m+mi}{20}\PYG{p}{,} \PYG{n}{min\PYGZus{}width}\PYG{o}{=}\PYG{l+m+mf}{0.01}\PYG{p}{)}
\PYG{n}{m} \PYG{o}{=} \PYG{n}{bym}\PYG{o}{.}\PYG{n}{Model}\PYG{p}{(}\PYG{n}{params}\PYG{o}{=}\PYG{n}{pl}\PYG{p}{,} \PYG{n}{output\PYGZus{}var}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{J}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

The code block above sets the ranges of values, spacing (linear by default, logarithmic as an option), and number of divisions (10 by default) for the two parameters, and initializes the model object using this parameter grid. We can also set a display name for plot labeling (TeX input is accepted in this field), units (also used in plotting, defaults to ‘unitless’), and minimum width beyond which a grid box won’t be subdivided along this dimension (defaults to 1\% of the value range in the appropriate spacing). Some of these parameters can also be set after data import using the \sphinxcode{\sphinxupquote{set\_param\_info()}} function, as in:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{set\PYGZus{}param\PYGZus{}info}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{J}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{units}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{mA/cm\PYGZdl{}\PYGZca{}2\PYGZdl{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{m}\PYG{o}{.}\PYG{n}{set\PYGZus{}param\PYGZus{}info}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{T}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{display\PYGZus{}name}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{temperature}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{units}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{K}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}


\section{Attaching Modeled Data}
\label{\detokenize{manual:attaching-modeled-data}}
Next, we need to attach the modeled data. If you’re using \sphinxcode{\sphinxupquote{bayesim}} to tell your model what points to run, you can call \sphinxcode{\sphinxupquote{list\_model\_pts\_to\_run()}} to write out an HDF5 file to pass to your forward model:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{list\PYGZus{}model\PYGZus{}pts\PYGZus{}to\PYGZus{}run}\PYG{p}{(}\PYG{n}{fpath}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{model\PYGZus{}inputs.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

You can also directly interface with your model by passing a Python callable, as in:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{attach\PYGZus{}model}\PYG{p}{(}\PYG{n}{mode}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{function}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{model\PYGZus{}data\PYGZus{}func}\PYG{o}{=}\PYG{n}{model\PYGZus{}func}\PYG{p}{)}
\end{sphinxVerbatim}

where \sphinxcode{\sphinxupquote{model\_func}} is a callable in your namespace that accepts dictionaries of inputs, one with keys of the EC’s and one of the fitting parameters (see {\hyperref[\detokenize{examples:id}]{\sphinxcrossref{\DUrole{std,std-ref}{ideal diode}}}} example).

However, typically, the model data will be precomputed and residing in an HDF5 file which will be attached to the model object:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{attach\PYGZus{}model}\PYG{p}{(}\PYG{n}{mode}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{file}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{model\PYGZus{}data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{model\PYGZus{}data.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

The {\hyperref[\detokenize{bayesics:model-uncertainty}]{\sphinxcrossref{\DUrole{std,std-ref}{model uncertainty}}}} also needs to be computed. This can be done either with a separate function call to \sphinxcode{\sphinxupquote{calc\_model\_unc()}}, or in a single step when attaching the model data:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{attach\PYGZus{}model}\PYG{p}{(}\PYG{n}{mode}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{file}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{model\PYGZus{}data\PYGZus{}path}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{model\PYGZus{}data.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{calc\PYGZus{}model\PYGZus{}unc}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{)}
\end{sphinxVerbatim}

The model uncertainty calculation can be somewhat expensive for large grids and will be parallelized by default on Unix-based systems.


\section{Performing the Inference}
\label{\detokenize{manual:performing-the-inference}}
Once experimental and model data and their associated uncertainties have been defined and the fitting parameters either explicitly specified or determined from the data, we can do Bayesian inference! The inference is performed by the \sphinxcode{\sphinxupquote{run()}} function. Details about what calculations are actually done and what they mean can be found on the {\hyperref[\detokenize{bayesics::doc}]{\sphinxcrossref{\DUrole{doc}{Technical Background}}}} page; here we will focus on the mechanics of the code.

First, a bounded uniform prior (equal probability in every grid box) is defined. Next, a piece of evidence (one experimental measurement, i.e. in this example a \((V, T, J)\) tuple) is chosen at random. The likelihood at each point in parameter space is computed conditioned on this piece of evidence as a Gaussian in the difference between the measured output and the simulated output at that point, with a standard deviation equal to the sum of the experimental error for that observation and the model uncertainty at that point:
\begin{equation}\label{equation:manual:manual:0}
\begin{split}\mathcal{P}(\{P\}|O_e(\{c\}_i)) \propto \exp\left(\frac{-(O_e(\{c\}_i)-O_m(\{P\},\{c\}_i))^2}{2(\sigma_e(\{c\}_i)+\sigma_m(\{P\},\{c\}_i))^2}\right)\end{split}
\end{equation}
In the {\hyperref[\detokenize{examples:id}]{\sphinxcrossref{\DUrole{std,std-ref}{ideal diode}}}} example, this means more specifically that
\begin{equation}\label{equation:manual:manual:1}
\begin{split}\mathcal{P}(B',n|J_{\text{meas}}(V_i,T_i)) \propto \exp\left(\frac{-(J_{\text{meas}}(V_i,T_i)-J_{\text{mod}}(B',n,V_i,T_i))^2}{2(\sigma_\text{meas}(V_i,T_i)+\sigma_{\text{mod}}(B',n,V_i,T_i))^2}\right)\end{split}
\end{equation}
This likelihood is multiplied with the prior and normalized to compute the posterior.

Next, \sphinxcode{\sphinxupquote{bayesim}} will check if the posterior distribution is “concentrated” enough. This concentration is defined by two optional parameters passed to \sphinxcode{\sphinxupquote{run()}}, \sphinxcode{\sphinxupquote{th\_pm}} and \sphinxcode{\sphinxupquote{th\_pv}}, both on the interval (0,1) and defaulting to 0.9 and 0.05, respectively. The posterior is sufficiently concentrated is \sphinxcode{\sphinxupquote{th\_pm}} of the probability mass resides in \sphinxcode{\sphinxupquote{th\_pv}} of the parameter space. (Entropy-based thresholding is planned as an option for a future release)

If the posterior is not sufficiently concentrated, the posterior is set to the prior, another piece of evidence chosen, and another Bayesian update performed until it is. Once the concentration threshold is met, the posterior is saved and another check is done for whether enough pieces of evidence have been used. The requisite number to use is defined by the \sphinxcode{\sphinxupquote{min\_num\_pts}} keyword in the \sphinxcode{\sphinxupquote{run()}} function and defaults to 80\% of the total number of observation data points imported. If not enough points have been used, the current posterior is saved, a new uniform prior is set and the process above repeated as many times as necessary for sufficient points to be used. The final posterior is then the average of all computed posteriors. \sphinxcode{\sphinxupquote{bayesim}} will inform you how many posteriors were averaged and how many observed data points were used.


\section{Visualizing the Output}
\label{\detokenize{manual:visualizing-the-output}}
\sphinxcode{\sphinxupquote{bayesim}} has a variety of capacities for data visualization.


\subsection{Plotting the PMF}
\label{\detokenize{manual:plotting-the-pmf}}
Visualizing the posterior distribution (probability mass function, or PMF) is done using the \sphinxcode{\sphinxupquote{visualize\_probs()}} function. It takes an optional argument of a filepath to save the image, and can also highlight a specific point in the parameter space to compare to using the \sphinxcode{\sphinxupquote{true\_vals}} keyword.


\subsection{Visualizing the Grid}
\label{\detokenize{manual:visualizing-the-grid}}
To visualize the current state of the parameter space grid, use \sphinxcode{\sphinxupquote{visualize\_grid()}}, which can also accept a path to save the imge as well as the \sphinxcode{\sphinxupquote{true\_vals}} keyword to highlight a particular point.


\subsection{Comparing the Data}
\label{\detokenize{manual:comparing-the-data}}
The \sphinxcode{\sphinxupquote{comparison\_plot()}} function can directly compare modeled to simulated data. It will produce a number of plots with the output variable on the y-axis and the previously specified EC x-variable on the x-axis. It accepts a few optional keywords:
\begin{description}
\item[{\sphinxcode{\sphinxupquote{ec\_vals}}}] \leavevmode
dict or list of dict, specific experimental
conditions at which to plot (values for x-axis EC are ignored)

\item[{\sphinxcode{\sphinxupquote{num\_ecs}}}] \leavevmode
int, number of (randomly chosen) EC’s at which to plot
(ignored if previous option is provided)

\item[{\sphinxcode{\sphinxupquote{num\_param\_pts}}}] \leavevmode
int, number of parameter space points for which to plot
modeled data (will choose the most probable)

\end{description}

In addition to a filepath to save the image as well as a flag to return average errors.


\section{Subdividing the Grid}
\label{\detokenize{manual:subdividing-the-grid}}
Once you have taken a look at your posterior PMF and compared observed and highest-probability modeled data, you’ll have a sense for whether you’d like to go to a higher fit precision by subdividing the parameter space grid. This can be done via a call to the \sphinxcode{\sphinxupquote{subdivide()}} function, which accepts one optional argument of \sphinxcode{\sphinxupquote{threshold\_prob}}, the minimum probability for a box to have in order to be subdivided. It defaults to 0.001. \sphinxcode{\sphinxupquote{bayesim}} will then divide every grid box meeting this threshold \sphinxstyleemphasis{as well as every box immediately neighboring it} into two along every parameter dimension, unless it is already narrower than the minimum width defined for that parameter.

\sphinxcode{\sphinxupquote{bayesim}} will inform you how many boxes were subdivided and also automatically save a file of the new points that need to be simulated using the model in order to perform another inference run. This new model data can be attached exactly as described {\hyperref[\detokenize{manual:attach-obs}]{\sphinxcrossref{\DUrole{std,std-ref}{above}}}} using the \sphinxcode{\sphinxupquote{attach\_observations()}} function, and then inference can proceed again.


\section{Miscellaneous}
\label{\detokenize{manual:miscellaneous}}

\subsection{Saving a state file}
\label{\detokenize{manual:saving-a-state-file}}
At any point during an analysis, the state of your \sphinxcode{\sphinxupquote{Model}} object can be saved using the \sphinxcode{\sphinxupquote{save\_state()}} function, and can be reloaded again using keywords in the \sphinxcode{\sphinxupquote{Model}} constructor:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{m}\PYG{o}{.}\PYG{n}{save\PYGZus{}state}\PYG{p}{(}\PYG{n}{filename}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{statefile.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{m} \PYG{o}{=} \PYG{n}{bym}\PYG{o}{.}\PYG{n}{Model}\PYG{p}{(}\PYG{n}{load\PYGZus{}state}\PYG{o}{=}\PYG{n+nb+bp}{True}\PYG{p}{,} \PYG{n}{state\PYGZus{}file}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{statefile.h5}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

This is useful, e.g., if you’re working interactively and want to be able to pick up again later without rerunning all the same code, or if you’d like to continue work on a different machine.


\subsection{Handling missing data}
\label{\detokenize{manual:handling-missing-data}}
Sometimes things go run when running a large number of simulations. \sphinxcode{\sphinxupquote{bayesim}} can handle cases where simulated data is missing (see the {\hyperref[\detokenize{examples:sns}]{\sphinxcrossref{\DUrole{std,std-ref}{SnS example}}}}). When computing likelihoods, if the simulated data for the EC in question isn’t present, it will just use what the uniform distribution probability would be for that point. The output of the \sphinxcode{\sphinxupquote{run()}} function will inform you how many times this happened on average over each Bayesian loop.


\chapter{Examples}
\label{\detokenize{examples:examples}}\label{\detokenize{examples::doc}}
This page is a (growing) list of example applications of \sphinxcode{\sphinxupquote{bayesim}}, attempting to showcase the variety of applicability as well as ways to run the code.


\section{Ideal diode solar cell}
\label{\detokenize{examples:id}}\label{\detokenize{examples:ideal-diode-solar-cell}}
The most self-contained example. Available to run in two different ways:


\subsection{Jupyter notebook}
\label{\detokenize{examples:jupyter-notebook}}
To run in Jupyter:
\begin{itemize}
\item {}
Download the \sphinxhref{https://github.com/PV-Lab/bayesim}{Github repository} and run from your local machine using \sphinxhref{http://jupyter.org}{Jupyter}

\end{itemize}

OR
\begin{itemize}
\item {}
Run in the cloud using Binder! \sphinxhref{https://mybinder.org/v2/gh/pv-lab/bayesim/master?filepath=examples\%2Fdiode\%2Fideal\_diode.ipynb}{\sphinxincludegraphics{{/Users/rachelkurchin/Dropbox (MIT)/MIT/Bayes_Project/bayesim/docs/_build/doctrees/images/https/mybinder.org/badge.svg/badge}.svg}}

\end{itemize}


\subsection{Command line}
\label{\detokenize{examples:command-line}}
To run from the command line:
\begin{enumerate}
\item {}
Download the \sphinxhref{https://github.com/PV-Lab/bayesim}{Github repository} (e.g. using \sphinxcode{\sphinxupquote{git clone}}) to your local machine.

\item {}
Navigate to the folder \sphinxcode{\sphinxupquote{bayesim/examples/command\_line/}}.

\item {}
…to be continued…(this example is not completely working yet)

\end{enumerate}


\section{Kinematics}
\label{\detokenize{examples:kinematics}}
Probably the simplest example, explained on the {\hyperref[\detokenize{bayesics::doc}]{\sphinxcrossref{\DUrole{doc}{Technical Background}}}} page. It exists in the \sphinxhref{https://github.com/PV-Lab/bayesim}{Github repo} under \sphinxcode{\sphinxupquote{examples/kinematics/kinematics.py}} and you can run it all in one go from a terminal (\sphinxcode{\sphinxupquote{python kinematics.py}}) or step-by-step in an IDE like Spyder.


\section{Tin Sulfide (SnS) solar cell}
\label{\detokenize{examples:tin-sulfide-sns-solar-cell}}\label{\detokenize{examples:sns}}
An example using an actual numerical model \textendash{} in this case, reproducing the fit (from \sphinxhref{https://www.sciencedirect.com/science/article/pii/S254243511730096X}{this paper}) of four material and interface properties in a tin sulfide solar cell. Also in Jupyter notebook form:
\begin{itemize}
\item {}
Download the \sphinxhref{https://github.com/PV-Lab/bayesim}{Github repository} and run from your local machine using \sphinxhref{http://jupyter.org}{Jupyter}

\end{itemize}

OR
\begin{itemize}
\item {}
Run in the cloud using Binder! \sphinxhref{https://mybinder.org/v2/gh/pv-lab/bayesim/master?filepath=examples\%2FSnS\%2FSnS\_fitting.ipynb}{\sphinxincludegraphics{{/Users/rachelkurchin/Dropbox (MIT)/MIT/Bayes_Project/bayesim/docs/_build/doctrees/images/https/mybinder.org/badge.svg/badge}.svg}}

\end{itemize}


\chapter{Future Features}
\label{\detokenize{futurefeatures:future-features}}\label{\detokenize{futurefeatures::doc}}
On this page, we maintain a list of planned future features of \sphinxcode{\sphinxupquote{bayesim}}. They’re listed under a variety of categories, in loosely descending order of priority within each.


\section{Visualization}
\label{\detokenize{futurefeatures:visualization}}\begin{itemize}
\item {}
visualizing model uncertainty on parameter grid

\item {}
visualizing measured vs. simulated data with experimental and model uncertainty

\item {}
option to generate a plot of which particular observed data was used in an inference run

\end{itemize}


\section{Other New Capabilities}
\label{\detokenize{futurefeatures:other-new-capabilities}}\begin{itemize}
\item {}
option for entropy-based thresholding as well as \sphinxtitleref{th\_pm} and \sphinxtitleref{th\_pv} in \sphinxcode{\sphinxupquote{run()}} function

\item {}
capability to pass a DataFrame objects to \sphinxcode{\sphinxupquote{attach\_model()}} and \sphinxcode{\sphinxupquote{attach\_observations()}} functions instead of just filepaths

\item {}
multiple output variables

\item {}
completely “closed-loop” version of \sphinxcode{\sphinxupquote{run()}} function that does subdivision as well (need a way to save a handle to a model function for running new simulations)

\item {}
interpolation of simulated data

\item {}
alternative error models

\item {}
alternative initial sampling states other than grids

\end{itemize}


\section{Efficiency/Speedup}
\label{\detokenize{futurefeatures:efficiency-speedup}}\begin{itemize}
\item {}
speed up \sphinxcode{\sphinxupquote{list\_model\_pts\_to\_run()}} function

\item {}
do some more code profiling to identify other particularly slow functions/components

\item {}
more parallelism generally

\end{itemize}


\section{Interfaces}
\label{\detokenize{futurefeatures:interfaces}}\begin{itemize}
\item {}
finish developing command-line interface

\item {}
build a GUI!

\end{itemize}


\chapter{Citing bayesim}
\label{\detokenize{citingbayesim:citing-bayesim}}\label{\detokenize{citingbayesim::doc}}
If you use the code, please consider citing

{[}placeholder{]}

\noindent\sphinxincludegraphics{{overview_figure}.png}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
