{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Thermoelectric data\n",
    "Models and data are from Danny/Kedar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules, Functions, and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`functions.py` has the Python implementations of all the helper functions (I used a previously written package, `fdint`, for the Fermi-Dirac integrals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "celldata = {}\n",
    "celldata['xdata'] = np.loadtxt('xdata.csv',delimiter=',')\n",
    "celldata['ydata'] = np.loadtxt('ydata.csv',delimiter=',')\n",
    "celldata['n'] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Python implementation\n",
    "I did a test evaluation in Matlab and Python with the same input parameters. Let's import the results and compare to make sure we're getting the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_in = [-2.499946233286e1,1.833885014595e-3,-2.2588468610036e-3,8.6217332036812e-4]\n",
    "test_y,test_S,test_Rou=tefunnew(celldata,test_in)\n",
    "matlab_y = np.loadtxt('matlab_y.csv',delimiter=',')\n",
    "matlab_S = np.loadtxt('matlab_S.csv',delimiter=',')\n",
    "matlab_Rou = np.loadtxt('matlab_Rou.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an average of a 0.27% difference (with a standard deviation of 0.00%) between the Matlab and Python implementations in the y output.\n"
     ]
    }
   ],
   "source": [
    "y_pct_diff=(test_y-matlab_y)/matlab_y\n",
    "print('There is an average of a %.2f%% difference (with a standard deviation of %.2f%%) between the Matlab and Python implementations in the y output.'%(round(100.0*np.mean(y_pct_diff),2),round(100.0*np.std(y_pct_diff),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an average of a 0.13% difference (with a standard deviation of 0.00%) between the Matlab and Python implementations in the S output.\n"
     ]
    }
   ],
   "source": [
    "S_pct_diff=(test_S-matlab_S)/matlab_S\n",
    "print('There is an average of a %.2f%% difference (with a standard deviation of %.2f%%) between the Matlab and Python implementations in the S output.'%(round(100.0*np.mean(S_pct_diff),2),round(100.0*np.std(S_pct_diff),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is an average of a -0.051% difference (with a standard deviation of 0.002%) between the Matlab and Python implementations in the Rou output.\n"
     ]
    }
   ],
   "source": [
    "Rou_pct_diff=(test_Rou-matlab_Rou)/matlab_Rou\n",
    "print('There is an average of a %.3f%% difference (with a standard deviation of %.3f%%) between the Matlab and Python implementations in the Rou output.'%(round(100.0*np.mean(Rou_pct_diff),3),round(100.0*np.std(Rou_pct_diff),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the differences aren't nothing, but they're small enough that I think we can work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with Bayesim\n",
    "Now let's do a fit to the data using the grid approach implemented in the `bayesim` code.\n",
    "### Import Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import bayesim.model as bym\n",
    "import bayesim.param_list as byp\n",
    "import functions as tefcns # model functions implemented in a separate file to keep this notebook tidy\n",
    "import deepdish as dd # for interacting with HDF5 files\n",
    "from joblib import Parallel, delayed # to parallelize model computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "First, we set up the list of parameters to be fit and their ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fp = byp.param_list()\n",
    "\"\"\"\n",
    "fp.add_fit_param(name='P0', val_range=[1e-34,1e-20], spacing='log', length=28, units='sec.')\n",
    "fp.add_fit_param(name='fs', val_range=[-1,2], length=21, units='eV')\n",
    "fp.add_fit_param(name='r', val_range=[-1,2], length=21)\n",
    "fp.add_fit_param(name='Z', val_range=[-10,10], length=20)\n",
    "\"\"\"\n",
    "fp.add_fit_param(name='P0', val_range=[1e-34,1e-20], spacing='log', length=7, units='sec.')\n",
    "fp.add_fit_param(name='fs', val_range=[-1,2], length=5, units='eV')\n",
    "fp.add_fit_param(name='r', val_range=[-1,2], length=5)\n",
    "fp.add_fit_param(name='Z', val_range=[-10,10], length=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ec = ['T','R','n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set up the `bayesim.model` object. All we need to feed in are the parameters, experimental conditions, and name of the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = bym.model(params=fp,ec=ec,output_var='P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach Experimental Observations\n",
    "The next thing to do is to attach the observed data. I reformatted it to work with `bayesim` and saved an HDF5 file. You can see the format in the Excel sheet `TE_expt_data.xlsx`. Here I use only every third point (integer values of resistances) to speed up model computation and also because that's probably enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified experimental conditions as ['n', 'T', 'R']. If this is wrong, rerun and explicitly specify them with attach_ec (make sure they match data file columns) or remove extra columns from data file.\n"
     ]
    }
   ],
   "source": [
    "#m.attach_observations(fpath='TE_expt_data.h5')\n",
    "m.attach_observations(fpath='TE_expt_data_sparse.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching the Model\n",
    "Next, we attach the model. In this example I'll precompute the modeled data and attach a file with the outputs. You could also attach the function used to do the modeling, but the code can't currently parallelize those computations so I do it outside `bayesim` to take advantage of both cores on my laptop.\n",
    "First we write out a file with the list of all simulation points. (it's good practice to write this out rather than keep it only as a Python object so we can pick up where we left off later)\n",
    "\n",
    "This next cell should take about 30 seconds to evaluate, but if you don't want to do the model computations yourself you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#m.list_model_pts_to_run('./sim_list.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell will actually do the model computations. On my two-core laptop, it takes about 24 minutes to evaluate. Assuming your processor supports multithreading (almost all modern ones do), you should set `n_jobs` to be twice the number of cores on your machine if you want to run this cell efficiently.\n",
    "\n",
    "You can also just skip this cell and instead evaluate the following one to just load in the results of the computation that I did. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sim_list = dd.io.load('./sim_list.h5')\n",
    "#outputs=Parallel(n_jobs=4,verbose=7)(delayed(tefunnew_singlept)(sim[1][m.ec_names],sim[1][m.param_names]) for sim in sim_list.iterrows())\n",
    "#sim_list['P'] = outputs\n",
    "#dd.io.save('sim_outputs.h5',sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.attach_model(mode='file',fpath='sim_outputs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
