{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Thermoelectric data\n",
    "Models and data are from Danny/Kedar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules, Functions, and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`functions.py` has the Python implementations of all the helper functions (I used a previously written package, `fdint`, for the Fermi-Dirac integrals)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celldata = {}\n",
    "celldata['xdata'] = np.loadtxt('xdata.csv',delimiter=',')\n",
    "celldata['ydata'] = np.loadtxt('ydata.csv',delimiter=',')\n",
    "celldata['n'] = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Python implementation\n",
    "I did a test evaluation in Matlab and Python with the same input parameters. Let's import the results and compare to make sure we're getting the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = [-2.499946233286e1,1.833885014595e-3,-2.2588468610036e-3,8.6217332036812e-4]\n",
    "test_y,test_S,test_Rou=tefunnew(celldata,test_in)\n",
    "matlab_y = np.loadtxt('matlab_y.csv',delimiter=',')\n",
    "matlab_S = np.loadtxt('matlab_S.csv',delimiter=',')\n",
    "matlab_Rou = np.loadtxt('matlab_Rou.csv',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pct_diff=(test_y-matlab_y)/matlab_y\n",
    "print('There is an average of a %.2f%% difference (with a standard deviation of %.2f%%) between the Matlab and Python implementations in the y output.'%(round(100.0*np.mean(y_pct_diff),2),round(100.0*np.std(y_pct_diff),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_pct_diff=(test_S-matlab_S)/matlab_S\n",
    "print('There is an average of a %.2f%% difference (with a standard deviation of %.2f%%) between the Matlab and Python implementations in the S output.'%(round(100.0*np.mean(S_pct_diff),2),round(100.0*np.std(S_pct_diff),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rou_pct_diff=(test_Rou-matlab_Rou)/matlab_Rou\n",
    "print('There is an average of a %.3f%% difference (with a standard deviation of %.3f%%) between the Matlab and Python implementations in the Rou output.'%(round(100.0*np.mean(Rou_pct_diff),3),round(100.0*np.std(Rou_pct_diff),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so the differences aren't nothing, but they're small enough that I think we can work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with Bayesim\n",
    "Now let's do a fit to the data using the grid approach implemented in the `bayesim` code.\n",
    "### Import Things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "import bayesim.model as bym\n",
    "import bayesim.param_list as byp\n",
    "import functions as tefcns # model functions implemented in a separate file to keep this notebook tidy\n",
    "import deepdish as dd # for interacting with HDF5 files\n",
    "from joblib import Parallel, delayed # to parallelize model computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize\n",
    "First, we set up the list of parameters to be fit and their ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = byp.param_list()\n",
    "\"\"\"\n",
    "fp.add_fit_param(name='P0', val_range=[1e-34,1e-20], spacing='log', length=28, units='sec.')\n",
    "fp.add_fit_param(name='fs', val_range=[-1,2], length=21, units='eV')\n",
    "fp.add_fit_param(name='r', val_range=[-1,2], length=21)\n",
    "fp.add_fit_param(name='Z', val_range=[-10,10], length=20)\n",
    "\"\"\"\n",
    "fp.add_fit_param(name='P0', val_range=[1e-34,1e-20], spacing='log', length=7, units='sec.')\n",
    "fp.add_fit_param(name='fs', val_range=[-1,2], length=5, units='eV')\n",
    "fp.add_fit_param(name='r', val_range=[-1,2], length=5)\n",
    "fp.add_fit_param(name='Z', val_range=[-10,10], length=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ['T','R','n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set up the `bayesim.model` object. All we need to feed in are the parameters, experimental conditions, and name of the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = bym.model(params=fp,ec=ec,output_var='P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach Experimental Observations\n",
    "The next thing to do is to attach the observed data. I reformatted it to work with `bayesim` and saved an HDF5 file. You can see the format in the Excel sheet `TE_expt_data.xlsx`. Here I use only every third point (integer values of resistances) to speed up model computation and also because that's probably enough data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified experimental conditions as ['n', 'T', 'R']. If this is wrong, rerun and explicitly specify them with attach_ec (make sure they match data file columns) or remove extra columns from data file.\n"
     ]
    }
   ],
   "source": [
    "#m.attach_observations(fpath='TE_expt_data.h5')\n",
    "m.attach_observations(fpath='TE_expt_data_sparse.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attaching the Model\n",
    "Next, we attach the model. In this example I'll precompute the modeled data and attach a file with the outputs. You could also attach the function used to do the modeling, but the code can't currently parallelize those computations so I do it outside `bayesim` to take advantage of both cores on my laptop.\n",
    "First we write out a file with the list of all simulation points. (it's good practice to write this out rather than keep it only as a Python object so we can pick up where we left off later)\n",
    "\n",
    "This next cell should take about 30 seconds to evaluate, but if you don't want to do the model computations yourself you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.list_model_pts_to_run('./sim_list.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell will actually do the model computations. On my two-core laptop, it takes about 24 minutes to evaluate. Assuming your processor supports multithreading (almost all modern ones do), you should set `n_jobs` to be twice the number of cores on your machine if you want to run this cell efficiently.\n",
    "\n",
    "You can also just skip this cell and instead evaluate the following one to just load in the results of the computation that I did. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim_list = dd.io.load('./sim_list.h5')\n",
    "#outputs=Parallel(n_jobs=4,verbose=7)(delayed(tefunnew_singlept)(sim[1][m.ec_names],sim[1][m.param_names]) for sim in sim_list.iterrows())\n",
    "#sim_list['P'] = outputs\n",
    "#dd.io.save('sim_outputs.h5',sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.attach_model(mode='file',fpath='sim_outputs.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a sparse grid like this, it's important that the error values we use (i.e. standard deviation of Gaussians used for likelihood) are big enough to reach between boxes. This function computes the distance in output variable between model boxes at every experimental condition point and adds it to a column in model_data called 'deltas.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P0</th>\n",
       "      <th>fs</th>\n",
       "      <th>r</th>\n",
       "      <th>Z</th>\n",
       "      <th>n</th>\n",
       "      <th>T</th>\n",
       "      <th>R</th>\n",
       "      <th>P</th>\n",
       "      <th>deltas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160245</th>\n",
       "      <td>1.000000e-25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>11.33330</td>\n",
       "      <td>1.448839e-01</td>\n",
       "      <td>5.764464e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111688</th>\n",
       "      <td>1.000000e-27</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.66670</td>\n",
       "      <td>1.927539e-40</td>\n",
       "      <td>2.327972e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36779</th>\n",
       "      <td>1.000000e-31</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.316220e+01</td>\n",
       "      <td>1.316220e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55685</th>\n",
       "      <td>1.000000e-31</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>8.937367e-45</td>\n",
       "      <td>1.019407e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95831</th>\n",
       "      <td>1.000000e-29</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>1.047737e-01</td>\n",
       "      <td>2.231783e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138863</th>\n",
       "      <td>1.000000e-27</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>3.044724e+00</td>\n",
       "      <td>2.060596e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156640</th>\n",
       "      <td>1.000000e-25</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.33333</td>\n",
       "      <td>1.324969e-42</td>\n",
       "      <td>8.747942e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240591</th>\n",
       "      <td>1.000000e-21</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.00000</td>\n",
       "      <td>1.225535e+00</td>\n",
       "      <td>1.714284e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128132</th>\n",
       "      <td>1.000000e-27</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11.00000</td>\n",
       "      <td>3.404713e-35</td>\n",
       "      <td>3.671342e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77651</th>\n",
       "      <td>1.000000e-29</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>9.33333</td>\n",
       "      <td>1.595828e-63</td>\n",
       "      <td>1.128167e-39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  P0   fs    r    Z     n      T         R             P  \\\n",
       "160245  1.000000e-25  0.5 -0.7  0.0  40.0   90.0  11.33330  1.448839e-01   \n",
       "111688  1.000000e-27 -0.7  0.5 -8.0  40.0   20.0  19.66670  1.927539e-40   \n",
       "36779   1.000000e-31 -0.7 -0.7 -4.0  40.0  130.0   8.00000  1.316220e+01   \n",
       "55685   1.000000e-31  0.5  1.1  0.0  40.0   10.0   6.00000  8.937367e-45   \n",
       "95831   1.000000e-29  1.1 -0.1 -8.0  40.0   70.0  16.00000  1.047737e-01   \n",
       "138863  1.000000e-27  1.7 -0.7  4.0  40.0  130.0  12.00000  3.044724e+00   \n",
       "156640  1.000000e-25 -0.1  1.1 -8.0  40.0   30.0   2.33333  1.324969e-42   \n",
       "240591  1.000000e-21  1.1 -0.7  8.0  40.0  100.0   8.00000  1.225535e+00   \n",
       "128132  1.000000e-27  0.5  1.1 -4.0  40.0  130.0  11.00000  3.404713e-35   \n",
       "77651   1.000000e-29 -0.7  1.1  0.0  40.0  120.0   9.33333  1.595828e-63   \n",
       "\n",
       "              deltas  \n",
       "160245  5.764464e-01  \n",
       "111688  2.327972e-16  \n",
       "36779   1.316220e+01  \n",
       "55685   1.019407e-21  \n",
       "95831   2.231783e-01  \n",
       "138863  2.060596e+00  \n",
       "156640  8.747942e-19  \n",
       "240591  1.714284e+00  \n",
       "128132  3.671342e-12  \n",
       "77651   1.128167e-39  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.calc_model_gradients()\n",
    "m.model_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, because our grid is super sparse, the deltas are actually larger than the actual output values right now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Bayes!\n",
    "The `run` function randomizes the order of observations and stops feeding them in by default when 80% of the probability mass resides in 5% of the parameter space. These parameters can be tuned using the input parameters `th_pm` (default 0.8) and `th_pv` (default 0.05).\n",
    "\n",
    "__If you don't want to have to run the new simulations yourself (they'll take longer than the first batch), don't run the code in this cell - I just left it so you can see what *was* run.__\n",
    "\n",
    "(Because the `run` function randomizes observations, if you run it, the subdivided cells will likely not match exactly and you'll get an error if you try to just load in the results from my new simulation run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.run()\n",
    "m.save_state(filename='states/state_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just load the model state that I saved and carry onward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#m = bym.model(load_state=True, state_file='states/state_1.h5')\n",
    "#%matplotlib inline\n",
    "#m.probs.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure what's going on with the upper left box right now. I'll fix it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subdivide!\n",
    "I've found that 0.001 seems to be a reasonable threshold probability for boxes to subdivide on the first round so that's the default value, but you can feed in other numbers for `threshold_prob` to this function.\n",
    "\n",
    "Note that the `subdivide` function divides not only boxes meeting the threshold but any boxes immediately neighboring those. It will also write out an HDF5 of the new simulations that need to be run; that step can take awhile (this cell takes a few minutes on my computer) because it's writing every combination of new parameter points AND experimental condition points.\n",
    "\n",
    "Again, if you don't want to run it, you can skip this cell and just use the `load_state` line in the next cell to start where I left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.subdivide()\n",
    "#m.save_state('states/state_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting that there were originally 875 boxes in our super sparse grid, so in this case a majority of them were subdivided, which isn't too surprising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run (more simulations and then) more inference!\n",
    "I ran the batch of new simulations on Peregrine; the results are in the file `new_sim_outputs_.h5` which we'll load in here to do the next round of inference.\n",
    "\n",
    "This cell takes about a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = bym.model(load_state=True,state_file='states/state_2.h5')\n",
    "#m.attach_model(mode='add',fpath='new_sim_outputs_1.h5')\n",
    "#m.save_state('states/state_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = bym.model(load_state=True,state_file='states/state_3.h5')\n",
    "#m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = byp.param_list()\n",
    "fp.add_fit_param(name='A',val_range=[0,1],length=4)\n",
    "fp.add_fit_param(name='B',val_range=[1,1000],length=3,spacing='log')\n",
    "tm = bym.model(params=fp,ec=['C'],output_var='O')\n",
    "new_probs = [0.05,0.02,0.17,0.06,0.07,0.09,0.23,0.05,0.04,0.06,0.08,0.08]\n",
    "tm.probs.points['prob']=new_probs\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style('default')\n",
    "tm.probs.visualize(just_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.probs.points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.probs.subdivide(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.probs.visualize(just_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.probs.points.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test non-gridded gradient calc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = points.iloc[17]\n",
    "def find_box(pt,bm,grid):\n",
    "    points_min_grps = {p:grid.groupby(by=[p+'_min']) for p in bm.param_names}\n",
    "    points_max_grps = {p:grid.groupby(by=[p+'_max']) for p in bm.param_names}\n",
    "    min_match = [set(np.concatenate([points_min_grps[p].groups[k] for k in list(points_min_grps[p].groups.keys()) if pt[p]>k])) for p in bm.param_names]\n",
    "    max_match = [set(np.concatenate([points_max_grps[p].groups[k] for k in list(points_max_grps[p].groups.keys()) if pt[p]<k])) for p in bm.param_names]\n",
    "    min_match = min_match[0].intersection(*min_match[1:])\n",
    "    max_match = max_match[0].intersection(*max_match[1:])\n",
    "    box_ind = list(min_match.intersection(max_match))\n",
    "    if len(box_ind)==0:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return box_ind[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = []\n",
    "for a in A_vals:\n",
    "    for b in B_vals:\n",
    "        pt = {'A':a,'B':b}\n",
    "        data.append([a,b,find_box(pt,tm,points)])\n",
    "        #print(pt,find_box(pt,tm,points))\n",
    "pd.DataFrame.from_records(data=data,columns=tm.param_names+['ind'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
